"""
æµ‹è¯•å¯¹è´¦åŠŸèƒ½
"""
import asyncio
import json
from pathlib import Path
from mcp_server.reconciliation_engine import ReconciliationEngine
from mcp_server.schema_loader import SchemaLoader

async def test_reconciliation():
    """æµ‹è¯•å¯¹è´¦åŠŸèƒ½"""
    
    print("=" * 70)
    print("å¼€å§‹å¯¹è´¦æµ‹è¯•")
    print("=" * 70)
    
    # 1. åŠ è½½ schema
    schema_file = "schemas/example_schema.json"
    print(f"\n1. åŠ è½½ Schema: {schema_file}")
    schema = SchemaLoader.load_from_file(schema_file)
    SchemaLoader.validate_schema(schema)
    print("   âœ… Schema éªŒè¯é€šè¿‡")
    
    # 2. å‡†å¤‡æ–‡ä»¶
    business_file = str(Path("test_data/business_flow.csv").absolute())
    finance_file = str(Path("test_data/ads_finance_d_inc_channel_details_20250101.csv").absolute())
    
    print(f"\n2. å‡†å¤‡æµ‹è¯•æ–‡ä»¶:")
    print(f"   ä¸šåŠ¡æ–‡ä»¶: {business_file}")
    print(f"   è´¢åŠ¡æ–‡ä»¶: {finance_file}")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(business_file).exists():
        print(f"   âŒ ä¸šåŠ¡æ–‡ä»¶ä¸å­˜åœ¨")
        return
    if not Path(finance_file).exists():
        print(f"   âŒ è´¢åŠ¡æ–‡ä»¶ä¸å­˜åœ¨")
        return
    print("   âœ… æ–‡ä»¶æ£€æŸ¥é€šè¿‡")
    
    # 3. åˆ›å»ºå¯¹è´¦å¼•æ“
    print(f"\n3. åˆ›å»ºå¯¹è´¦å¼•æ“...")
    engine = ReconciliationEngine(schema)
    print("   âœ… å¯¹è´¦å¼•æ“åˆ›å»ºæˆåŠŸ")
    
    # 4. æ‰§è¡Œå¯¹è´¦
    print(f"\n4. æ‰§è¡Œå¯¹è´¦ï¼ˆè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼‰...")
    print("-" * 70)
    
    file_paths = [business_file, finance_file]
    result = engine.reconcile(file_paths)
    
    print("-" * 70)
    print("\n5. å¯¹è´¦ç»“æœ:")
    
    # æ‘˜è¦
    summary = result['summary']
    print(f"\n   ğŸ“Š å¯¹è´¦æ‘˜è¦:")
    print(f"      ä¸šåŠ¡è®°å½•æ€»æ•°: {summary.total_business_records}")
    print(f"      è´¢åŠ¡è®°å½•æ€»æ•°: {summary.total_finance_records}")
    print(f"      åŒ¹é…è®°å½•æ•°:   {summary.matched_records}")
    print(f"      æœªåŒ¹é…è®°å½•æ•°: {summary.unmatched_records}")
    
    # é—®é¢˜ç»Ÿè®¡
    issues = result['issues']
    print(f"\n   âš ï¸  é—®é¢˜è¯¦æƒ…ï¼ˆå…± {len(issues)} ä¸ªé—®é¢˜ï¼‰:")
    
    # æŒ‰é—®é¢˜ç±»å‹ç»Ÿè®¡
    issue_types = {}
    for issue in issues:
        issue_type = issue.issue_type
        issue_types[issue_type] = issue_types.get(issue_type, 0) + 1
    
    for issue_type, count in issue_types.items():
        print(f"      {issue_type}: {count} ä¸ª")
    
    # æ˜¾ç¤ºå‰10ä¸ªé—®é¢˜ç¤ºä¾‹
    print(f"\n   ğŸ“‹ é—®é¢˜ç¤ºä¾‹ï¼ˆå‰10ä¸ªï¼‰:")
    for i, issue in enumerate(issues[:10], 1):
        print(f"\n      é—®é¢˜ {i}:")
        print(f"        è®¢å•å·: {issue.order_id}")
        print(f"        ç±»å‹:   {issue.issue_type}")
        print(f"        ä¸šåŠ¡å€¼: {issue.business_value}")
        print(f"        è´¢åŠ¡å€¼: {issue.finance_value}")
        print(f"        è¯¦æƒ…:   {issue.detail}")
    
    # å…ƒæ•°æ®
    metadata = result['metadata']
    print(f"\n   ğŸ“ å…ƒæ•°æ®:")
    print(f"      ä¸šåŠ¡æ–‡ä»¶æ•°: {metadata.business_file_count}")
    print(f"      è´¢åŠ¡æ–‡ä»¶æ•°: {metadata.finance_file_count}")
    print(f"      è§„åˆ™ç‰ˆæœ¬:   {metadata.rule_version}")
    print(f"      å¤„ç†æ—¶é—´:   {metadata.processed_at}")
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    result_file = "results/test_result.json"
    Path("results").mkdir(exist_ok=True)
    
    result_dict = {
        "summary": summary.to_dict(),
        "issues": [issue.to_dict() for issue in issues],
        "metadata": metadata.to_dict()
    }
    
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(result_dict, f, ensure_ascii=False, indent=2)
    
    print(f"\n6. ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
    
    print("\n" + "=" * 70)
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("=" * 70)

if __name__ == "__main__":
    asyncio.run(test_reconciliation())

